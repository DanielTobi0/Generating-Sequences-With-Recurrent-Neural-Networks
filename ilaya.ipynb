{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download fr_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import spacy\n",
    "# import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 1800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {'validation': 'fr-en/validation-00000-of-00001.parquet'}\n",
    "dataset = load_dataset(path='wmt/wmt14', trust_remote_code=True, data_files=data_files)\n",
    "data = pd.DataFrame(dataset['validation'])\n",
    "\n",
    "train, temp = train_test_split(data, test_size=0.4, random_state=0)\n",
    "test, validation = train_test_split(temp, test_size=0.5, random_state=0)\n",
    "\n",
    "def process_translations(df):\n",
    "    en_texts = [item['en'] for item in df['translation']]\n",
    "    fr_texts = [item['fr'] for item in df['translation']]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'en': en_texts,\n",
    "        'fr': fr_texts\n",
    "    })\n",
    "\n",
    "train_processed = process_translations(train)\n",
    "test_processed = process_translations(test)\n",
    "validation_processed = process_translations(validation)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_processed.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_processed.reset_index(drop=True))\n",
    "validation_dataset = Dataset.from_pandas(validation_processed.reset_index(drop=True))\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset,\n",
    "    'validation': validation_dataset\n",
    "})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataset, data\n",
    "# del train, temp, test, validation\n",
    "# del process_translations, train_processed, test_processed, validation_dataset\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d008936ec044d5873bddbf4c5aaea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad829ce5564abd87e5e91e98be6833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f2d6f127e747e9a852eda62f5982d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "fr_nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "def tokenize_example(example, en_nlp, fr_nlp, max_length, sos_token, eos_token):\n",
    "    en_tokens = [token.text.lower() for token in en_nlp.tokenizer(example['en'])][:max_length]\n",
    "    fr_tokens = [token.text.lower() for token in fr_nlp.tokenizer(example['fr'])][:max_length]\n",
    "\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    fr_tokens = [sos_token] + fr_tokens + [eos_token]\n",
    "\n",
    "    return {'en_tokens': en_tokens, 'fr_tokens': fr_tokens} \n",
    "\n",
    "    \n",
    "max_length = 1000\n",
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "\n",
    "fn_kwargs = {\n",
    "    'en_nlp': en_nlp,\n",
    "    'fr_nlp': fr_nlp,\n",
    "    'max_length': max_length,\n",
    "    'sos_token': sos_token,\n",
    "    'eos_token': eos_token,\n",
    "}\n",
    "\n",
    "train_data, test_data, validation_data = (\n",
    "    ds['train'],\n",
    "    ds['test'],\n",
    "    ds['validation'],\n",
    ")\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "validation_data = validation_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def lang_str_int(lang, nlp):\n",
    "    lang_vocab = []\n",
    "    special_vocab = ['<unk>', '<pad>', '<sos>', '<eos>'] \n",
    "\n",
    "    flattened_list = [token.text.lower() for sentence in lang for token in nlp.tokenizer(sentence)]\n",
    "    lang_count = Counter(flattened_list)\n",
    "    lang_words = [string for string, freq in lang_count.items() if freq >= 2]\n",
    "\n",
    "    lang_vocab = special_vocab + lang_words\n",
    "    # lang_vocab.extend(special_vocab)\n",
    "    # lang_vocab.extend(lang_words)\n",
    "\n",
    "    lang_str2int = {ch: i for i, ch in enumerate(lang_vocab)}\n",
    "    lang_int2str = {i: ch for i, ch in enumerate(lang_vocab)}\n",
    "\n",
    "    return lang_str2int, lang_int2str\n",
    "\n",
    "en = process_translations(data)['en'].tolist()\n",
    "fr = process_translations(data)['fr'].tolist()\n",
    "\n",
    "fr_str2int, fr_int2str = lang_str_int(fr, fr_nlp)\n",
    "en_str2int, en_int2str = lang_str_int(en, en_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60f8514fbbb42ebbffdd7e9bc52f00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb7c4c229fa475eaa6f6793f4a62fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94caf9032f347a786d4edd204b0df69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def token_to_int(example, str2int):\n",
    "    return [str2int.get(token, str2int['<unk>']) for token in example]\n",
    "\n",
    "def tokens_to_ids(example):\n",
    "    example['en_ids'] = token_to_int(example['en_tokens'], en_str2int)\n",
    "    example['fr_ids'] = token_to_int(example['fr_tokens'], fr_str2int)\n",
    "    return example\n",
    "\n",
    "train_data = train_data.map(tokens_to_ids)\n",
    "test_data = test_data.map(tokens_to_ids)\n",
    "validation_data = validation_data.map(tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f90393c1d7477291e168a46ac9ef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e8f759f02048bb8b1d4bbffb758d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a35d05930a74b71903a3aa79c1fb8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reverse_source_lang(example):\n",
    "    example['en_ids'] = example['en_ids'][::-1]\n",
    "    return example\n",
    "\n",
    "train_data = train_data.map(reverse_source_lang)\n",
    "test_data = test_data.map(reverse_source_lang)\n",
    "validation_data = validation_data.map(reverse_source_lang)\n",
    "\n",
    "train_data.set_format(\n",
    "    type='torch',\n",
    "    columns=['en_ids', 'fr_ids'],\n",
    "    output_all_columns=False\n",
    ")\n",
    "test_data.set_format(\n",
    "    type='torch',\n",
    "    columns=['en_ids', 'fr_ids'],\n",
    "    output_all_columns=False\n",
    ")\n",
    "validation_data.set_format(\n",
    "    type='torch',\n",
    "    columns=['en_ids', 'fr_ids'],\n",
    "    output_all_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example['en_ids'] for example in batch]\n",
    "        batch_fr_ids = [example['fr_ids'] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_fr_ids = nn.utils.rnn.pad_sequence(batch_fr_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            'en_ids': batch_en_ids,\n",
    "            'fr_ids': batch_fr_ids\n",
    "        }\n",
    "        return batch\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "PAD_INDEX = en_str2int[pad_token]\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, PAD_INDEX, shuffle=True)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, PAD_INDEX, shuffle=False)\n",
    "validation_data_loader = get_data_loader(validation_data, batch_size, PAD_INDEX, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([76, 128]), torch.Size([86, 128]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = next(iter(train_data_loader))\n",
    "result['en_ids'].shape, result['fr_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input_ = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input_))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden,cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, trg_len):\n",
    "        ''' \n",
    "        src: [src_len, batch_size]\n",
    "        trg: [trg_len, batch_size]\n",
    "        trg_len: length o\n",
    "        '''\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        input_ = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input_, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            \n",
    "            top1 = output.argmax(1)\n",
    "            input_ = top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_tensors = next(iter(validation_data_loader))\n",
    "en_sample = lang_tensors['en_ids']\n",
    "fr_sample = lang_tensors['fr_ids']\n",
    "\n",
    "input_dim = len(en_str2int)\n",
    "output_dim = len(fr_str2int)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CLIP = 1\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim, \n",
    "    encoder_embedding_dim, \n",
    "    hidden_dim, \n",
    "    n_layers,\n",
    "    encoder_dropout\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim, \n",
    "    decoder_embedding_dim, \n",
    "    hidden_dim, \n",
    "    n_layers,\n",
    "    decoder_dropout\n",
    ")\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    torch.nn.init.uniform_(param, a=-0.08, b=0.08)\n",
    "\n",
    "for param in decoder.parameters():\n",
    "    torch.nn.init.uniform_(param, a=-0.08, b=0.08)\n",
    "    \n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.7)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=fr_str2int['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        src = batch['en_ids'].to(device)\n",
    "        trg = batch['fr_ids'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg, trg.shape[0])\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['en_ids'].to(device)\n",
    "            trg = batch['fr_ids'].to(device)\n",
    "\n",
    "            output = model(src, trg, trg.shape[0])            \n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    mins = int(elapsed_time / 60)\n",
    "    secs = int(elapsed_time - (mins * 60))\n",
    "    return mins, secs\n",
    "\n",
    "N_EPOCHS = 2\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, validation_data_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "\n",
    "# torch.save(model.state_dict(), 'seq2seq_model_no_teacher_forcing.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'seq2seq_model_no_teacher_forcing.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, encoder, decoder, src_vocab, trg_vocab, device, max_len=50):\n",
    "    \"\"\"\n",
    "    sentence: list of token indices\n",
    "    src_vocab: mapping from indices to tokens for source language\n",
    "    trg_vocab: mapping from indices to tokens for target language\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    src_tensor = torch.LongTensor(sentence).unsqueeze(1).to(device)  # [src_len, 1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = encoder(src_tensor)\n",
    "    \n",
    "    # Start with <sos> token\n",
    "    trg_indexes = [fr_str2int['<sos>']]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = decoder(trg_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == fr_str2int['<eos>']:\n",
    "            break\n",
    "    \n",
    "    # Convert indices to tokens\n",
    "    trg_tokens = [int2fr[token] for token in trg_indexes]\n",
    "    \n",
    "    return trg_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated French Sentence: <sos> , , , , , de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = [\n",
    "    en_str2int['<sos>'], \n",
    "    en_str2int['i'], \n",
    "    en_str2int['am'], \n",
    "    en_str2int['a'], \n",
    "    en_str2int['student'], \n",
    "    en_str2int['<eos>']\n",
    "]\n",
    "\n",
    "# Translate\n",
    "translation = translate_sentence(sample_sentence, encoder, decoder, en_str2int, fr_str2int, device)\n",
    "\n",
    "print('Translated French Sentence:', ' '.join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "\n",
    "def calculate_bleu(data, model, device, max_len=50):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        src = datum['en_ids']\n",
    "        trg = datum['fr_ids']\n",
    "        \n",
    "        src_sentence = src.tolist()[0]\n",
    "        trg_sentence = trg.tolist()[0]\n",
    "        \n",
    "        pred_tokens = translate_sentence(src_sentence, model.encoder, model.decoder, en_str2int, fr_str2int, device, max_len)\n",
    "        pred_tokens = pred_tokens[1:-1]  # Remove <sos> and <eos>\n",
    "        \n",
    "        trg_tokens = [int2fr[token] for token in trg_sentence if token not in [fr_str2int['<sos>'], fr_str2int['<eos>'], fr_str2int['<pad>']]]\n",
    "        \n",
    "        trgs.append([trg_tokens])\n",
    "        pred_trgs.append(pred_tokens)\n",
    "    \n",
    "    return corpus_bleu(trgs, pred_trgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu(validation_data_loader, model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HomePC\\AppData\\Local\\Temp\\ipykernel_22716\\4284413809.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('seq2seq_model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4340, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4707, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=4707, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving\n",
    "torch.save({\n",
    "    'encoder_state_dict': encoder.state_dict(),\n",
    "    'decoder_state_dict': decoder.state_dict(),\n",
    "}, 'seq2seq_model.pth')\n",
    "\n",
    "# Loading\n",
    "checkpoint = torch.load('seq2seq_model.pth')\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
